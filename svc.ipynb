{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 360,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Boruta\r\n",
      "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\r\n",
      "     |████████████████████████████████| 56 kB 431 kB/s            \r\n",
      "\u001B[?25hRequirement already satisfied: scipy>=0.17.0 in ./venv/lib/python3.10/site-packages (from Boruta) (1.10.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in ./venv/lib/python3.10/site-packages (from Boruta) (1.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.10.4 in ./venv/lib/python3.10/site-packages (from Boruta) (1.23.5)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.10/site-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./venv/lib/python3.10/site-packages (from scikit-learn>=0.17.1->Boruta) (1.2.0)\r\n",
      "Installing collected packages: Boruta\r\n",
      "Successfully installed Boruta-0.3\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 23.0 is available.\r\n",
      "You should consider upgrading via the '/Users/admin/Documents/MscProject/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install Boruta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Granger causality, machine learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [],
   "source": [
    "gci_data = np.load('gci_nls_cc200_vector.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "data": {
      "text/plain": "   0         1         2         3         4         5         6      \\\n0    1.0  0.232827  0.310001  0.022694  0.171940  0.201924  1.564648   \n1    1.0  0.000000  0.000000  0.034329  0.000000  0.000000  0.000000   \n2    1.0  0.000000  0.211977  0.063180  0.000000  0.000000  0.000000   \n3    1.0  0.003462  0.176266  0.119884  0.000000  0.000000  0.061226   \n4    1.0  0.348111  0.137865  0.170946  0.007856  0.477393  0.028955   \n\n      7         8         9      ...     39991     39992     39993  39994  \\\n0  0.507979  0.157911  0.261360  ...  0.000000  0.000000  0.365369    0.0   \n1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000    0.0   \n2  0.000000  0.000000  0.000000  ...  0.300281  0.064557  0.000000    0.0   \n3  0.000000  0.272025  0.083786  ...  0.000000  0.000000  0.000000    0.0   \n4  0.093623  0.025476  0.086795  ...  0.082194  0.000000  0.270727    0.0   \n\n      39995     39996     39997     39998  39999  40000  \n0  0.159129  0.000000  0.000000  0.000000    1.0    1.0  \n1  0.000000  0.000000  0.000000  0.000000    1.0    1.0  \n2  0.314101  0.000000  0.087941  0.244485    1.0    1.0  \n3  0.000000  0.000000  0.130785  0.000000    1.0    1.0  \n4  0.139575  0.108761  0.019303  0.329178    1.0    1.0  \n\n[5 rows x 40001 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>39991</th>\n      <th>39992</th>\n      <th>39993</th>\n      <th>39994</th>\n      <th>39995</th>\n      <th>39996</th>\n      <th>39997</th>\n      <th>39998</th>\n      <th>39999</th>\n      <th>40000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.232827</td>\n      <td>0.310001</td>\n      <td>0.022694</td>\n      <td>0.171940</td>\n      <td>0.201924</td>\n      <td>1.564648</td>\n      <td>0.507979</td>\n      <td>0.157911</td>\n      <td>0.261360</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.365369</td>\n      <td>0.0</td>\n      <td>0.159129</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.034329</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.211977</td>\n      <td>0.063180</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.300281</td>\n      <td>0.064557</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.314101</td>\n      <td>0.000000</td>\n      <td>0.087941</td>\n      <td>0.244485</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.003462</td>\n      <td>0.176266</td>\n      <td>0.119884</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.061226</td>\n      <td>0.000000</td>\n      <td>0.272025</td>\n      <td>0.083786</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.130785</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.348111</td>\n      <td>0.137865</td>\n      <td>0.170946</td>\n      <td>0.007856</td>\n      <td>0.477393</td>\n      <td>0.028955</td>\n      <td>0.093623</td>\n      <td>0.025476</td>\n      <td>0.086795</td>\n      <td>...</td>\n      <td>0.082194</td>\n      <td>0.000000</td>\n      <td>0.270727</td>\n      <td>0.0</td>\n      <td>0.139575</td>\n      <td>0.108761</td>\n      <td>0.019303</td>\n      <td>0.329178</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40001 columns</p>\n</div>"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gci_df = pd.DataFrame(gci_data)\n",
    "gci_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/w62sf0c17hs15h730mmdkmj40000gn/T/ipykernel_64877/4089041766.py:1: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  gci_df.iloc[:,-1]=gci_df.iloc[:,-1].astype(int)\n"
     ]
    }
   ],
   "source": [
    "gci_df.iloc[:,-1]=gci_df.iloc[:,-1].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "diagonals = [i for i in range(gci_df.shape[1]) if len(gci_df.iloc[:,i].unique())==1.0] # get indexes of columns containing diagonal values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "gci_df.drop(diagonals, axis=1, inplace=True) #drop columns containing diagonal data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "data": {
      "text/plain": "      1         2         3         4         5         6         7      \\\n0  0.232827  0.310001  0.022694  0.171940  0.201924  1.564648  0.507979   \n1  0.000000  0.000000  0.034329  0.000000  0.000000  0.000000  0.000000   \n2  0.000000  0.211977  0.063180  0.000000  0.000000  0.000000  0.000000   \n3  0.003462  0.176266  0.119884  0.000000  0.000000  0.061226  0.000000   \n4  0.348111  0.137865  0.170946  0.007856  0.477393  0.028955  0.093623   \n\n      8         9        10     ...     39990     39991     39992     39993  \\\n0  0.157911  0.261360  0.02722  ...  0.000000  0.000000  0.000000  0.365369   \n1  0.000000  0.000000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n2  0.000000  0.000000  0.00000  ...  0.140119  0.300281  0.064557  0.000000   \n3  0.272025  0.083786  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n4  0.025476  0.086795  0.00000  ...  0.000000  0.082194  0.000000  0.270727   \n\n   39994     39995     39996     39997     39998  40000  \n0    0.0  0.159129  0.000000  0.000000  0.000000      1  \n1    0.0  0.000000  0.000000  0.000000  0.000000      1  \n2    0.0  0.314101  0.000000  0.087941  0.244485      1  \n3    0.0  0.000000  0.000000  0.130785  0.000000      1  \n4    0.0  0.139575  0.108761  0.019303  0.329178      1  \n\n[5 rows x 39801 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>39990</th>\n      <th>39991</th>\n      <th>39992</th>\n      <th>39993</th>\n      <th>39994</th>\n      <th>39995</th>\n      <th>39996</th>\n      <th>39997</th>\n      <th>39998</th>\n      <th>40000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.232827</td>\n      <td>0.310001</td>\n      <td>0.022694</td>\n      <td>0.171940</td>\n      <td>0.201924</td>\n      <td>1.564648</td>\n      <td>0.507979</td>\n      <td>0.157911</td>\n      <td>0.261360</td>\n      <td>0.02722</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.365369</td>\n      <td>0.0</td>\n      <td>0.159129</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.034329</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.211977</td>\n      <td>0.063180</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.140119</td>\n      <td>0.300281</td>\n      <td>0.064557</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.314101</td>\n      <td>0.000000</td>\n      <td>0.087941</td>\n      <td>0.244485</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.003462</td>\n      <td>0.176266</td>\n      <td>0.119884</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.061226</td>\n      <td>0.000000</td>\n      <td>0.272025</td>\n      <td>0.083786</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.130785</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.348111</td>\n      <td>0.137865</td>\n      <td>0.170946</td>\n      <td>0.007856</td>\n      <td>0.477393</td>\n      <td>0.028955</td>\n      <td>0.093623</td>\n      <td>0.025476</td>\n      <td>0.086795</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.082194</td>\n      <td>0.000000</td>\n      <td>0.270727</td>\n      <td>0.0</td>\n      <td>0.139575</td>\n      <td>0.108761</td>\n      <td>0.019303</td>\n      <td>0.329178</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39801 columns</p>\n</div>"
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gci_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [],
   "source": [
    "X = gci_df.iloc[:,:-1].to_numpy()\n",
    "y = np.array([1 if i==1 else 0 for i in gci_df.iloc[:,-1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t1\n",
      "Tentative: \t3\n",
      "Rejected: \t39796\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t1\n",
      "Tentative: \t3\n",
      "Rejected: \t39796\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t1\n",
      "Tentative: \t3\n",
      "Rejected: \t39796\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t39796\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t39796\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t39796\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t39796\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t39796\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t39796\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t39796\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t39796\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t39796\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t39796\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t39796\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t39796\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t39796\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t0\n",
      "Rejected: \t39796\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t0\n",
      "Rejected: \t39796\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=2)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
    "\n",
    "# find all relevant features - 5 features should be selected\n",
    "feat_selector.fit(X, y)\n",
    "\n",
    "# check selected features - first 5 features are selected\n",
    "feat_selector.support_\n",
    "\n",
    "# check ranking of features\n",
    "feat_selector.ranking_\n",
    "\n",
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.17419931, 0.        , 1.        ],\n       [0.        , 0.        , 0.        , 0.        , 1.        ],\n       [0.        , 0.        , 0.06850366, 0.        , 1.        ],\n       ...,\n       [0.19721642, 0.06062376, 0.34622007, 0.        , 1.        ],\n       [0.02483044, 0.01356252, 0.        , 0.        , 1.        ],\n       [0.        , 0.        , 0.        , 0.63635521, 1.        ]])"
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[X_filtered,y]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [
    {
     "data": {
      "text/plain": "1026"
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_filtered[:,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot: >"
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=X_filtered[:,0], y=X_filtered[:,1], hue=y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2)\n",
    "scores = []\n",
    "for train, test in cv.split(X_filtered, y):\n",
    "    # *ConnectivityMeasure* can output the estimated subjects coefficients\n",
    "    # as a 1D arrays through the parameter *vectorize*.\n",
    "\n",
    "    classifier = SVC(kernel='rbf').fit(X_filtered[train], y[train])\n",
    "    # make predictions for the left-out test subjects\n",
    "    predictions = classifier.predict(X_filtered[test])\n",
    "    # store the accuracy for this cross-validation fold\n",
    "    score = accuracy_score(y[test], predictions)\n",
    "    scores.append(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5456310679611651"
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Large scale granger causality, machine learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "data = np.load('/Users/admin/Documents/MscProject/gci_cc200_vectorised.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "   0         1         2         3         4         5         6      \\\n0    1.0  0.000000  0.000000  0.000000  0.000000  0.009432  0.000000   \n1    1.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n2    1.0  0.000000  0.001848  0.000000  0.000000  0.012329  0.003704   \n3    1.0  0.000000  0.000625  0.000339  0.000000  0.000000  0.000000   \n4    1.0  0.000719  0.000000  0.000378  0.007974  0.022800  0.000151   \n\n      7         8         9      ...     39991     39992     39993     39994  \\\n0  0.000000  0.001403  0.000000  ...  0.000939  0.000000  0.000622  0.000000   \n1  0.014210  0.019196  0.000000  ...  0.000000  0.000000  0.000582  0.001591   \n2  0.003097  0.005602  0.005504  ...  0.005032  0.002467  0.000460  0.005617   \n3  0.000000  0.005610  0.000000  ...  0.000000  0.000000  0.001647  0.000000   \n4  0.010994  0.000000  0.003348  ...  0.000000  0.003095  0.003939  0.001385   \n\n      39995     39996     39997     39998  39999  40000  \n0  0.000000  0.018050  0.000826  0.003743    1.0    1.0  \n1  0.000000  0.005735  0.000092  0.031975    1.0    1.0  \n2  0.004939  0.008758  0.000000  0.020097    1.0    1.0  \n3  0.001952  0.000000  0.000655  0.010060    1.0    1.0  \n4  0.000000  0.000000  0.005272  0.000000    1.0    1.0  \n\n[5 rows x 40001 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>39991</th>\n      <th>39992</th>\n      <th>39993</th>\n      <th>39994</th>\n      <th>39995</th>\n      <th>39996</th>\n      <th>39997</th>\n      <th>39998</th>\n      <th>39999</th>\n      <th>40000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.009432</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.001403</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000939</td>\n      <td>0.000000</td>\n      <td>0.000622</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.018050</td>\n      <td>0.000826</td>\n      <td>0.003743</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.014210</td>\n      <td>0.019196</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000582</td>\n      <td>0.001591</td>\n      <td>0.000000</td>\n      <td>0.005735</td>\n      <td>0.000092</td>\n      <td>0.031975</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.001848</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012329</td>\n      <td>0.003704</td>\n      <td>0.003097</td>\n      <td>0.005602</td>\n      <td>0.005504</td>\n      <td>...</td>\n      <td>0.005032</td>\n      <td>0.002467</td>\n      <td>0.000460</td>\n      <td>0.005617</td>\n      <td>0.004939</td>\n      <td>0.008758</td>\n      <td>0.000000</td>\n      <td>0.020097</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000625</td>\n      <td>0.000339</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005610</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.001647</td>\n      <td>0.000000</td>\n      <td>0.001952</td>\n      <td>0.000000</td>\n      <td>0.000655</td>\n      <td>0.010060</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.000719</td>\n      <td>0.000000</td>\n      <td>0.000378</td>\n      <td>0.007974</td>\n      <td>0.022800</td>\n      <td>0.000151</td>\n      <td>0.010994</td>\n      <td>0.000000</td>\n      <td>0.003348</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.003095</td>\n      <td>0.003939</td>\n      <td>0.001385</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005272</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40001 columns</p>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/w62sf0c17hs15h730mmdkmj40000gn/T/ipykernel_64877/3430961961.py:1: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:,-1]=df.iloc[:,-1].astype(int)\n"
     ]
    }
   ],
   "source": [
    "df.iloc[:,-1]=df.iloc[:,-1].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "diagonals = [i for i in range(df.shape[1]) if len(df.iloc[:,i].unique())==1] # get indexes of columns containing diagonal values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "df.drop(diagonals, axis=1, inplace=True) #drop columns containing diagonal data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "         1         2         3         4         5         6         7      \\\n0     0.000000  0.000000  0.000000  0.000000  0.009432  0.000000  0.000000   \n1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.014210   \n2     0.000000  0.001848  0.000000  0.000000  0.012329  0.003704  0.003097   \n3     0.000000  0.000625  0.000339  0.000000  0.000000  0.000000  0.000000   \n4     0.000719  0.000000  0.000378  0.007974  0.022800  0.000151  0.010994   \n...        ...       ...       ...       ...       ...       ...       ...   \n1021  0.002805  0.000000  0.000000  0.000098  0.000000  0.000000  0.002056   \n1022  0.000000  0.008851  0.001434  0.004161  0.006538  0.000000  0.000453   \n1023  0.000000  0.000718  0.001614  0.000000  0.000000  0.002350  0.000000   \n1024  0.015773  0.000000  0.000000  0.000000  0.000000  0.009825  0.009090   \n1025  0.000000  0.000000  0.005743  0.001744  0.001245  0.000000  0.013191   \n\n         8         9         10     ...     39990     39991     39992  \\\n0     0.001403  0.000000  0.000000  ...  0.003441  0.000939  0.000000   \n1     0.019196  0.000000  0.000000  ...  0.000066  0.000000  0.000000   \n2     0.005602  0.005504  0.000000  ...  0.000000  0.005032  0.002467   \n3     0.005610  0.000000  0.000219  ...  0.037120  0.000000  0.000000   \n4     0.000000  0.003348  0.000000  ...  0.000000  0.000000  0.003095   \n...        ...       ...       ...  ...       ...       ...       ...   \n1021  0.000000  0.001238  0.004056  ...  0.007953  0.000675  0.009182   \n1022  0.005415  0.000662  0.000000  ...  0.003379  0.016427  0.000000   \n1023  0.004809  0.004014  0.000000  ...  0.004236  0.000000  0.000000   \n1024  0.000000  0.001475  0.009274  ...  0.002308  0.005384  0.000000   \n1025  0.000000  0.003402  0.001286  ...  0.000000  0.000000  0.000000   \n\n         39993     39994     39995     39996     39997     39998  40000  \n0     0.000622  0.000000  0.000000  0.018050  0.000826  0.003743      1  \n1     0.000582  0.001591  0.000000  0.005735  0.000092  0.031975      1  \n2     0.000460  0.005617  0.004939  0.008758  0.000000  0.020097      1  \n3     0.001647  0.000000  0.001952  0.000000  0.000655  0.010060      1  \n4     0.003939  0.001385  0.000000  0.000000  0.005272  0.000000      1  \n...        ...       ...       ...       ...       ...       ...    ...  \n1021  0.014095  0.000000  0.000000  0.000000  0.005108  0.000000      1  \n1022  0.000000  0.000000  0.007626  0.007087  0.000000  0.004480      1  \n1023  0.008340  0.000320  0.003060  0.010233  0.011922  0.002335      1  \n1024  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000      1  \n1025  0.000000  0.005629  0.000000  0.012394  0.009681  0.000000      1  \n\n[1026 rows x 39801 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>39990</th>\n      <th>39991</th>\n      <th>39992</th>\n      <th>39993</th>\n      <th>39994</th>\n      <th>39995</th>\n      <th>39996</th>\n      <th>39997</th>\n      <th>39998</th>\n      <th>40000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.009432</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.001403</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.003441</td>\n      <td>0.000939</td>\n      <td>0.000000</td>\n      <td>0.000622</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.018050</td>\n      <td>0.000826</td>\n      <td>0.003743</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.014210</td>\n      <td>0.019196</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000066</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000582</td>\n      <td>0.001591</td>\n      <td>0.000000</td>\n      <td>0.005735</td>\n      <td>0.000092</td>\n      <td>0.031975</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.001848</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012329</td>\n      <td>0.003704</td>\n      <td>0.003097</td>\n      <td>0.005602</td>\n      <td>0.005504</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.005032</td>\n      <td>0.002467</td>\n      <td>0.000460</td>\n      <td>0.005617</td>\n      <td>0.004939</td>\n      <td>0.008758</td>\n      <td>0.000000</td>\n      <td>0.020097</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000625</td>\n      <td>0.000339</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005610</td>\n      <td>0.000000</td>\n      <td>0.000219</td>\n      <td>...</td>\n      <td>0.037120</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.001647</td>\n      <td>0.000000</td>\n      <td>0.001952</td>\n      <td>0.000000</td>\n      <td>0.000655</td>\n      <td>0.010060</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000719</td>\n      <td>0.000000</td>\n      <td>0.000378</td>\n      <td>0.007974</td>\n      <td>0.022800</td>\n      <td>0.000151</td>\n      <td>0.010994</td>\n      <td>0.000000</td>\n      <td>0.003348</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003095</td>\n      <td>0.003939</td>\n      <td>0.001385</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005272</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1021</th>\n      <td>0.002805</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000098</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002056</td>\n      <td>0.000000</td>\n      <td>0.001238</td>\n      <td>0.004056</td>\n      <td>...</td>\n      <td>0.007953</td>\n      <td>0.000675</td>\n      <td>0.009182</td>\n      <td>0.014095</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005108</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1022</th>\n      <td>0.000000</td>\n      <td>0.008851</td>\n      <td>0.001434</td>\n      <td>0.004161</td>\n      <td>0.006538</td>\n      <td>0.000000</td>\n      <td>0.000453</td>\n      <td>0.005415</td>\n      <td>0.000662</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.003379</td>\n      <td>0.016427</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.007626</td>\n      <td>0.007087</td>\n      <td>0.000000</td>\n      <td>0.004480</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1023</th>\n      <td>0.000000</td>\n      <td>0.000718</td>\n      <td>0.001614</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002350</td>\n      <td>0.000000</td>\n      <td>0.004809</td>\n      <td>0.004014</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.004236</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.008340</td>\n      <td>0.000320</td>\n      <td>0.003060</td>\n      <td>0.010233</td>\n      <td>0.011922</td>\n      <td>0.002335</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1024</th>\n      <td>0.015773</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.009825</td>\n      <td>0.009090</td>\n      <td>0.000000</td>\n      <td>0.001475</td>\n      <td>0.009274</td>\n      <td>...</td>\n      <td>0.002308</td>\n      <td>0.005384</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1025</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005743</td>\n      <td>0.001744</td>\n      <td>0.001245</td>\n      <td>0.000000</td>\n      <td>0.013191</td>\n      <td>0.000000</td>\n      <td>0.003402</td>\n      <td>0.001286</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005629</td>\n      <td>0.000000</td>\n      <td>0.012394</td>\n      <td>0.009681</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1026 rows × 39801 columns</p>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].to_numpy()\n",
    "y = np.array([1 if i==1 else 0 for i in df.iloc[:,-1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "PCA(n_components=0.6)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=0.6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=0.6)</pre></div></div></div></div></div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpca = PCA(n_components=0.60)\n",
    "kpca.fit(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "features = kpca.transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.19199043,  0.08117812,  0.01683551, ...,  0.00827599,\n         0.02719637,  0.01064703],\n       [ 0.11673179,  0.20474664,  0.06622118, ...,  0.00725239,\n        -0.02842953, -0.003269  ],\n       [ 0.28208514,  0.05810256,  0.10390982, ...,  0.02404216,\n         0.0116526 ,  0.01130496],\n       ...,\n       [ 0.02522307,  0.03057172, -0.12135646, ..., -0.12808825,\n        -0.0201539 , -0.00574662],\n       [ 0.11029762, -0.14313994, -0.10962507, ...,  0.13313592,\n         0.09382017,  0.02411624],\n       [ 0.19534193, -0.09219146, -0.09119775, ..., -0.06590279,\n         0.0048919 ,  0.02950453]])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2)\n",
    "\n",
    "for train, test in cv.split(features, y):\n",
    "        # *ConnectivityMeasure* can output the estimated subjects coefficients\n",
    "        # as a 1D arrays through the parameter *vectorize*.\n",
    "\n",
    "    classifier = LinearSVC().fit(X[train], y[train])\n",
    "        # make predictions for the left-out test subjects\n",
    "    predictions = classifier.predict(X[test])\n",
    "        # store the accuracy for this cross-validation fold\n",
    "    score= accuracy_score(y[test], predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5388349514563107"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t39800\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t39796\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t39796\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t39796\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t2\n",
      "Rejected: \t39796\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t0\n",
      "Rejected: \t39796\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t0\n",
      "Rejected: \t39796\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
    "\n",
    "# find all relevant features - 5 features should be selected\n",
    "feat_selector.fit(X, y)\n",
    "\n",
    "# check selected features - first 5 features are selected\n",
    "feat_selector.support_\n",
    "\n",
    "# check ranking of features\n",
    "feat_selector.ranking_\n",
    "\n",
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2)\n",
    "\n",
    "for train, test in cv.split(X_filtered, y):\n",
    "        # *ConnectivityMeasure* can output the estimated subjects coefficients\n",
    "        # as a 1D arrays through the parameter *vectorize*.\n",
    "\n",
    "    classifier = RandomForestClassifier().fit(X_filtered[train], y[train])\n",
    "        # make predictions for the left-out test subjects\n",
    "    predictions = classifier.predict(X_filtered[test])\n",
    "        # store the accuracy for this cross-validation fold\n",
    "    score= accuracy_score(y[test], predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5048543689320388"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2)\n",
    "\n",
    "for train, test in cv.split(X_filtered, y):\n",
    "    # *ConnectivityMeasure* can output the estimated subjects coefficients\n",
    "    # as a 1D arrays through the parameter *vectorize*.\n",
    "\n",
    "    classifier = SVC(kernel='rbf').fit(X_filtered[train], y[train])\n",
    "    # make predictions for the left-out test subjects\n",
    "    predictions = classifier.predict(X_filtered[test])\n",
    "    # store the accuracy for this cross-validation fold\n",
    "    score = accuracy_score(y[test], predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5631067961165048"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2)\n",
    "\n",
    "for train, test in cv.split(X_filtered, y):\n",
    "    # *ConnectivityMeasure* can output the estimated subjects coefficients\n",
    "    # as a 1D arrays through the parameter *vectorize*.\n",
    "\n",
    "    classifier = LinearSVC().fit(X_filtered[train], y[train])\n",
    "    # make predictions for the left-out test subjects\n",
    "    predictions = classifier.predict(X_filtered[test])\n",
    "    # store the accuracy for this cross-validation fold\n",
    "    score = accuracy_score(y[test], predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5194174757281553"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FC machine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "data = np.load('/Users/admin/Documents/MscProject/fc_cc200_vectorised.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "      0         1         2         3         4         5         6      \\\n0 -0.318127 -0.069796 -0.036556 -0.163779  0.154582 -0.468522  0.149931   \n1  0.248915  0.138000 -0.209563 -0.142492 -0.541118 -0.220420 -0.038429   \n2  0.138845  0.060143 -0.074200 -0.062667  0.065521  0.034017 -0.131597   \n3 -0.255444  0.107162 -0.054165  0.085518 -0.007979 -0.277307 -0.052372   \n4 -0.377935 -0.060415 -0.005243 -0.431189 -0.117298 -0.135625  0.153580   \n\n      7         8         9      ...     19891     19892     19893     19894  \\\n0  0.085749 -0.091261 -0.097561  ... -0.013454  0.288202  0.346534  0.169769   \n1 -0.579570 -0.276240  0.080674  ...  0.047489 -0.217907  0.152274 -0.022263   \n2 -0.272950 -0.267307  0.056912  ...  0.064907 -0.101845  0.258160 -0.350446   \n3  0.300137  0.187776 -0.014143  ...  0.168408  0.214707  0.010837 -0.220701   \n4  0.104868  0.151153 -0.198125  ... -0.043606 -0.051302 -0.137138 -0.207220   \n\n      19895     19896     19897     19898     19899  19900  \n0  0.402399  0.235802  0.328523  0.022539  0.275308    1.0  \n1  0.387047  0.030468  0.100718  0.109483 -0.272489    1.0  \n2  0.157305 -0.163685 -0.071646  0.114257 -0.299283    1.0  \n3  0.121951  0.140008 -0.150833  0.227749 -0.012394    1.0  \n4 -0.160206 -0.037513  0.401884  0.275285 -0.304601    1.0  \n\n[5 rows x 19901 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>19891</th>\n      <th>19892</th>\n      <th>19893</th>\n      <th>19894</th>\n      <th>19895</th>\n      <th>19896</th>\n      <th>19897</th>\n      <th>19898</th>\n      <th>19899</th>\n      <th>19900</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.318127</td>\n      <td>-0.069796</td>\n      <td>-0.036556</td>\n      <td>-0.163779</td>\n      <td>0.154582</td>\n      <td>-0.468522</td>\n      <td>0.149931</td>\n      <td>0.085749</td>\n      <td>-0.091261</td>\n      <td>-0.097561</td>\n      <td>...</td>\n      <td>-0.013454</td>\n      <td>0.288202</td>\n      <td>0.346534</td>\n      <td>0.169769</td>\n      <td>0.402399</td>\n      <td>0.235802</td>\n      <td>0.328523</td>\n      <td>0.022539</td>\n      <td>0.275308</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.248915</td>\n      <td>0.138000</td>\n      <td>-0.209563</td>\n      <td>-0.142492</td>\n      <td>-0.541118</td>\n      <td>-0.220420</td>\n      <td>-0.038429</td>\n      <td>-0.579570</td>\n      <td>-0.276240</td>\n      <td>0.080674</td>\n      <td>...</td>\n      <td>0.047489</td>\n      <td>-0.217907</td>\n      <td>0.152274</td>\n      <td>-0.022263</td>\n      <td>0.387047</td>\n      <td>0.030468</td>\n      <td>0.100718</td>\n      <td>0.109483</td>\n      <td>-0.272489</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.138845</td>\n      <td>0.060143</td>\n      <td>-0.074200</td>\n      <td>-0.062667</td>\n      <td>0.065521</td>\n      <td>0.034017</td>\n      <td>-0.131597</td>\n      <td>-0.272950</td>\n      <td>-0.267307</td>\n      <td>0.056912</td>\n      <td>...</td>\n      <td>0.064907</td>\n      <td>-0.101845</td>\n      <td>0.258160</td>\n      <td>-0.350446</td>\n      <td>0.157305</td>\n      <td>-0.163685</td>\n      <td>-0.071646</td>\n      <td>0.114257</td>\n      <td>-0.299283</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.255444</td>\n      <td>0.107162</td>\n      <td>-0.054165</td>\n      <td>0.085518</td>\n      <td>-0.007979</td>\n      <td>-0.277307</td>\n      <td>-0.052372</td>\n      <td>0.300137</td>\n      <td>0.187776</td>\n      <td>-0.014143</td>\n      <td>...</td>\n      <td>0.168408</td>\n      <td>0.214707</td>\n      <td>0.010837</td>\n      <td>-0.220701</td>\n      <td>0.121951</td>\n      <td>0.140008</td>\n      <td>-0.150833</td>\n      <td>0.227749</td>\n      <td>-0.012394</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.377935</td>\n      <td>-0.060415</td>\n      <td>-0.005243</td>\n      <td>-0.431189</td>\n      <td>-0.117298</td>\n      <td>-0.135625</td>\n      <td>0.153580</td>\n      <td>0.104868</td>\n      <td>0.151153</td>\n      <td>-0.198125</td>\n      <td>...</td>\n      <td>-0.043606</td>\n      <td>-0.051302</td>\n      <td>-0.137138</td>\n      <td>-0.207220</td>\n      <td>-0.160206</td>\n      <td>-0.037513</td>\n      <td>0.401884</td>\n      <td>0.275285</td>\n      <td>-0.304601</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 19901 columns</p>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/w62sf0c17hs15h730mmdkmj40000gn/T/ipykernel_64877/4128129977.py:1: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:,-1]=df.iloc[:,-1].astype(int)\n"
     ]
    }
   ],
   "source": [
    "df.iloc[:,-1]=df.iloc[:,-1].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].to_numpy()\n",
    "y = np.array([1 if i==1 else 0 for i in df.iloc[:,-1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t19900\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t19900\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t19900\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t19900\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t19900\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t19900\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t19900\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t496\n",
      "Rejected: \t19404\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t110\n",
      "Tentative: \t386\n",
      "Rejected: \t19404\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t110\n",
      "Tentative: \t386\n",
      "Rejected: \t19404\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t110\n",
      "Tentative: \t386\n",
      "Rejected: \t19404\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t126\n",
      "Tentative: \t308\n",
      "Rejected: \t19466\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t126\n",
      "Tentative: \t308\n",
      "Rejected: \t19466\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t126\n",
      "Tentative: \t308\n",
      "Rejected: \t19466\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t126\n",
      "Tentative: \t308\n",
      "Rejected: \t19466\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t137\n",
      "Tentative: \t267\n",
      "Rejected: \t19496\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t137\n",
      "Tentative: \t267\n",
      "Rejected: \t19496\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t137\n",
      "Tentative: \t267\n",
      "Rejected: \t19496\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t146\n",
      "Tentative: \t258\n",
      "Rejected: \t19496\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t146\n",
      "Tentative: \t246\n",
      "Rejected: \t19508\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t146\n",
      "Tentative: \t246\n",
      "Rejected: \t19508\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t155\n",
      "Tentative: \t237\n",
      "Rejected: \t19508\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t155\n",
      "Tentative: \t226\n",
      "Rejected: \t19519\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t155\n",
      "Tentative: \t226\n",
      "Rejected: \t19519\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t155\n",
      "Tentative: \t226\n",
      "Rejected: \t19519\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t163\n",
      "Tentative: \t218\n",
      "Rejected: \t19519\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t163\n",
      "Tentative: \t218\n",
      "Rejected: \t19519\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t163\n",
      "Tentative: \t218\n",
      "Rejected: \t19519\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t171\n",
      "Tentative: \t210\n",
      "Rejected: \t19519\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t171\n",
      "Tentative: \t203\n",
      "Rejected: \t19526\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t171\n",
      "Tentative: \t203\n",
      "Rejected: \t19526\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t179\n",
      "Tentative: \t195\n",
      "Rejected: \t19526\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t179\n",
      "Tentative: \t190\n",
      "Rejected: \t19531\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t185\n",
      "Tentative: \t184\n",
      "Rejected: \t19531\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t185\n",
      "Tentative: \t184\n",
      "Rejected: \t19531\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t185\n",
      "Tentative: \t184\n",
      "Rejected: \t19531\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t191\n",
      "Tentative: \t178\n",
      "Rejected: \t19531\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t191\n",
      "Tentative: \t176\n",
      "Rejected: \t19533\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t191\n",
      "Tentative: \t176\n",
      "Rejected: \t19533\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t192\n",
      "Tentative: \t175\n",
      "Rejected: \t19533\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t192\n",
      "Tentative: \t173\n",
      "Rejected: \t19535\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t192\n",
      "Tentative: \t173\n",
      "Rejected: \t19535\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t194\n",
      "Tentative: \t171\n",
      "Rejected: \t19535\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t194\n",
      "Tentative: \t166\n",
      "Rejected: \t19540\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t194\n",
      "Tentative: \t166\n",
      "Rejected: \t19540\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t196\n",
      "Tentative: \t164\n",
      "Rejected: \t19540\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t196\n",
      "Tentative: \t160\n",
      "Rejected: \t19544\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t196\n",
      "Tentative: \t160\n",
      "Rejected: \t19544\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t198\n",
      "Tentative: \t158\n",
      "Rejected: \t19544\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t198\n",
      "Tentative: \t158\n",
      "Rejected: \t19544\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t198\n",
      "Tentative: \t149\n",
      "Rejected: \t19553\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t198\n",
      "Tentative: \t149\n",
      "Rejected: \t19553\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t198\n",
      "Tentative: \t149\n",
      "Rejected: \t19553\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t200\n",
      "Tentative: \t147\n",
      "Rejected: \t19553\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t200\n",
      "Tentative: \t147\n",
      "Rejected: \t19553\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t200\n",
      "Tentative: \t146\n",
      "Rejected: \t19554\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t200\n",
      "Tentative: \t140\n",
      "Rejected: \t19560\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t200\n",
      "Tentative: \t140\n",
      "Rejected: \t19560\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t203\n",
      "Tentative: \t137\n",
      "Rejected: \t19560\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t203\n",
      "Tentative: \t137\n",
      "Rejected: \t19560\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t203\n",
      "Tentative: \t137\n",
      "Rejected: \t19560\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t205\n",
      "Tentative: \t135\n",
      "Rejected: \t19560\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t205\n",
      "Tentative: \t135\n",
      "Rejected: \t19560\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t205\n",
      "Tentative: \t135\n",
      "Rejected: \t19560\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t206\n",
      "Tentative: \t134\n",
      "Rejected: \t19560\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t206\n",
      "Tentative: \t133\n",
      "Rejected: \t19561\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t208\n",
      "Tentative: \t131\n",
      "Rejected: \t19561\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t208\n",
      "Tentative: \t127\n",
      "Rejected: \t19565\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t208\n",
      "Tentative: \t127\n",
      "Rejected: \t19565\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t209\n",
      "Tentative: \t126\n",
      "Rejected: \t19565\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t209\n",
      "Tentative: \t126\n",
      "Rejected: \t19565\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t209\n",
      "Tentative: \t126\n",
      "Rejected: \t19565\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t209\n",
      "Tentative: \t126\n",
      "Rejected: \t19565\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t209\n",
      "Tentative: \t126\n",
      "Rejected: \t19565\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t123\n",
      "Rejected: \t19565\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t123\n",
      "Rejected: \t19565\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t213\n",
      "Tentative: \t122\n",
      "Rejected: \t19565\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t213\n",
      "Tentative: \t122\n",
      "Rejected: \t19565\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t213\n",
      "Tentative: \t122\n",
      "Rejected: \t19565\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t213\n",
      "Tentative: \t122\n",
      "Rejected: \t19565\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t213\n",
      "Tentative: \t122\n",
      "Rejected: \t19565\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t213\n",
      "Tentative: \t122\n",
      "Rejected: \t19565\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t119\n",
      "Rejected: \t19565\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t119\n",
      "Rejected: \t19565\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t119\n",
      "Rejected: \t19565\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t119\n",
      "Rejected: \t19565\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t117\n",
      "Rejected: \t19567\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t117\n",
      "Rejected: \t19567\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t117\n",
      "Rejected: \t19567\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t117\n",
      "Rejected: \t19567\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t117\n",
      "Rejected: \t19567\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t117\n",
      "Rejected: \t19567\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t114\n",
      "Rejected: \t19570\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t114\n",
      "Rejected: \t19570\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t114\n",
      "Rejected: \t19570\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t114\n",
      "Rejected: \t19570\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t114\n",
      "Rejected: \t19570\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t113\n",
      "Rejected: \t19570\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t113\n",
      "Rejected: \t19570\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t53\n",
      "Rejected: \t19570\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
    "\n",
    "# find all relevant features - 5 features should be selected\n",
    "feat_selector.fit(X, y)\n",
    "\n",
    "# check selected features - first 5 features are selected\n",
    "feat_selector.support_\n",
    "\n",
    "# check ranking of features\n",
    "feat_selector.ranking_\n",
    "\n",
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=0.2)\n",
    "scores = []\n",
    "for train, test in cv.split(X_filtered, y):\n",
    "        # *ConnectivityMeasure* can output the estimated subjects coefficients\n",
    "        # as a 1D arrays through the parameter *vectorize*.\n",
    "\n",
    "    classifier = RandomForestClassifier().fit(X_filtered[train], y[train])\n",
    "        # make predictions for the left-out test subjects\n",
    "    predictions = classifier.predict(X_filtered[test])\n",
    "        # store the accuracy for this cross-validation fold\n",
    "    score= accuracy_score(y[test], predictions)\n",
    "    scores.append(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7300970873786408"
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=0.2)\n",
    "scores = []\n",
    "for train, test in cv.split(X_filtered, y):\n",
    "    # *ConnectivityMeasure* can output the estimated subjects coefficients\n",
    "    # as a 1D arrays through the parameter *vectorize*.\n",
    "\n",
    "    classifier = SVC(kernel='rbf').fit(X_filtered[train], y[train])\n",
    "    # make predictions for the left-out test subjects\n",
    "    predictions = classifier.predict(X_filtered[test])\n",
    "    # store the accuracy for this cross-validation fold\n",
    "    score = accuracy_score(y[test], predictions)\n",
    "    scores.append(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7485436893203883"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2)\n",
    "\n",
    "for train, test in cv.split(X_filtered, y):\n",
    "    # *ConnectivityMeasure* can output the estimated subjects coefficients\n",
    "    # as a 1D arrays through the parameter *vectorize*.\n",
    "\n",
    "    classifier = LinearSVC().fit(X_filtered[train], y[train])\n",
    "    # make predictions for the left-out test subjects\n",
    "    predictions = classifier.predict(X_filtered[test])\n",
    "    # store the accuracy for this cross-validation fold\n",
    "    score = accuracy_score(y[test], predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6941747572815534"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "X_train,y_train, X_val, y_val = train_test_split(X_filtered,y, test_size=0.2, random_state=2, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.        , 0.        ],\n       [0.26037874, 0.        , 0.        , 0.        ],\n       [0.        , 0.57402742, 0.04546703, 0.        ],\n       ...,\n       [0.        , 0.41175431, 0.17929614, 0.077432  ],\n       [0.09295521, 0.17961145, 0.        , 0.05321868],\n       [0.14298477, 0.        , 0.155806  , 0.        ]])"
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}